{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/rnn-recurrent-neural-networks-how-to-successfully-model-sequential-data-in-python-5a0b9e494f92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/Keras: 2.12.0\n",
      "pandas: 1.5.2\n",
      "numpy: 1.22.3\n",
      "sklearn: 1.2.0\n",
      "plotly: 5.13.1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras # for building Neural Networks\n",
    "print('Tensorflow/Keras: %s' % keras.__version__) # print version\n",
    "from keras.models import Sequential # for creating a linear stack of layers for our Neural Network\n",
    "from keras import Input # for instantiating a keras tensor\n",
    "from keras.layers import Dense, SimpleRNN # for creating regular densely-connected NN layers and RNN layers\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd # for data manipulation\n",
    "print('pandas: %s' % pd.__version__) # print version\n",
    "import numpy as np # for data manipulation\n",
    "print('numpy: %s' % np.__version__) # print version\n",
    "import math # to help with data reshaping of the data\n",
    "\n",
    "# Sklearn\n",
    "import sklearn # for model evaluation\n",
    "print('sklearn: %s' % sklearn.__version__) # print version\n",
    "from sklearn.model_selection import train_test_split # for splitting the data into train and test samples\n",
    "from sklearn.metrics import mean_squared_error # for model evaluation metrics\n",
    "from sklearn.preprocessing import MinMaxScaler # for feature scaling\n",
    "\n",
    "# Visualization\n",
    "import plotly \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "print('plotly: %s' % plotly.__version__) # print version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>EEG.AF3</th>\n",
       "      <th>EEG.F7</th>\n",
       "      <th>EEG.F3</th>\n",
       "      <th>EEG.FC5</th>\n",
       "      <th>EEG.T7</th>\n",
       "      <th>EEG.P7</th>\n",
       "      <th>EEG.O1</th>\n",
       "      <th>EEG.O2</th>\n",
       "      <th>EEG.P8</th>\n",
       "      <th>EEG.T8</th>\n",
       "      <th>EEG.FC6</th>\n",
       "      <th>EEG.F4</th>\n",
       "      <th>EEG.F8</th>\n",
       "      <th>EEG.AF4</th>\n",
       "      <th>POW.AF3.Theta</th>\n",
       "      <th>POW.AF3.Alpha</th>\n",
       "      <th>POW.AF3.BetaL</th>\n",
       "      <th>POW.AF3.BetaH</th>\n",
       "      <th>POW.AF3.Gamma</th>\n",
       "      <th>POW.F7.Theta</th>\n",
       "      <th>POW.F7.Alpha</th>\n",
       "      <th>POW.F7.BetaL</th>\n",
       "      <th>POW.F7.BetaH</th>\n",
       "      <th>POW.F7.Gamma</th>\n",
       "      <th>POW.F3.Theta</th>\n",
       "      <th>POW.F3.Alpha</th>\n",
       "      <th>POW.F3.BetaL</th>\n",
       "      <th>POW.F3.BetaH</th>\n",
       "      <th>POW.F3.Gamma</th>\n",
       "      <th>POW.FC5.Theta</th>\n",
       "      <th>POW.FC5.Alpha</th>\n",
       "      <th>POW.FC5.BetaL</th>\n",
       "      <th>POW.FC5.BetaH</th>\n",
       "      <th>POW.FC5.Gamma</th>\n",
       "      <th>POW.T7.Theta</th>\n",
       "      <th>POW.T7.Alpha</th>\n",
       "      <th>POW.T7.BetaL</th>\n",
       "      <th>POW.T7.BetaH</th>\n",
       "      <th>POW.T7.Gamma</th>\n",
       "      <th>POW.P7.Theta</th>\n",
       "      <th>POW.P7.Alpha</th>\n",
       "      <th>POW.P7.BetaL</th>\n",
       "      <th>POW.P7.BetaH</th>\n",
       "      <th>POW.P7.Gamma</th>\n",
       "      <th>POW.O1.Theta</th>\n",
       "      <th>POW.O1.Alpha</th>\n",
       "      <th>POW.O1.BetaL</th>\n",
       "      <th>POW.O1.BetaH</th>\n",
       "      <th>POW.O1.Gamma</th>\n",
       "      <th>POW.O2.Theta</th>\n",
       "      <th>POW.O2.Alpha</th>\n",
       "      <th>POW.O2.BetaL</th>\n",
       "      <th>POW.O2.BetaH</th>\n",
       "      <th>POW.O2.Gamma</th>\n",
       "      <th>POW.P8.Theta</th>\n",
       "      <th>POW.P8.Alpha</th>\n",
       "      <th>POW.P8.BetaL</th>\n",
       "      <th>POW.P8.BetaH</th>\n",
       "      <th>POW.P8.Gamma</th>\n",
       "      <th>POW.T8.Theta</th>\n",
       "      <th>POW.T8.Alpha</th>\n",
       "      <th>POW.T8.BetaL</th>\n",
       "      <th>POW.T8.BetaH</th>\n",
       "      <th>POW.T8.Gamma</th>\n",
       "      <th>POW.FC6.Theta</th>\n",
       "      <th>POW.FC6.Alpha</th>\n",
       "      <th>POW.FC6.BetaL</th>\n",
       "      <th>POW.FC6.BetaH</th>\n",
       "      <th>POW.FC6.Gamma</th>\n",
       "      <th>POW.F4.Theta</th>\n",
       "      <th>POW.F4.Alpha</th>\n",
       "      <th>POW.F4.BetaL</th>\n",
       "      <th>POW.F4.BetaH</th>\n",
       "      <th>POW.F4.Gamma</th>\n",
       "      <th>POW.F8.Theta</th>\n",
       "      <th>POW.F8.Alpha</th>\n",
       "      <th>POW.F8.BetaL</th>\n",
       "      <th>POW.F8.BetaH</th>\n",
       "      <th>POW.F8.Gamma</th>\n",
       "      <th>POW.AF4.Theta</th>\n",
       "      <th>POW.AF4.Alpha</th>\n",
       "      <th>POW.AF4.BetaL</th>\n",
       "      <th>POW.AF4.BetaH</th>\n",
       "      <th>POW.AF4.Gamma</th>\n",
       "      <th>subject_understood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4210.641113</td>\n",
       "      <td>4179.102539</td>\n",
       "      <td>4287.948730</td>\n",
       "      <td>4235.384766</td>\n",
       "      <td>4207.948730</td>\n",
       "      <td>4165.000000</td>\n",
       "      <td>4135.897461</td>\n",
       "      <td>4170.000000</td>\n",
       "      <td>4155.384766</td>\n",
       "      <td>4157.179688</td>\n",
       "      <td>4610.384766</td>\n",
       "      <td>4388.846191</td>\n",
       "      <td>4413.461426</td>\n",
       "      <td>4499.743652</td>\n",
       "      <td>1.859064</td>\n",
       "      <td>1.488007</td>\n",
       "      <td>0.294396</td>\n",
       "      <td>0.459987</td>\n",
       "      <td>0.188314</td>\n",
       "      <td>1.779598</td>\n",
       "      <td>0.620659</td>\n",
       "      <td>0.497043</td>\n",
       "      <td>0.344509</td>\n",
       "      <td>0.178338</td>\n",
       "      <td>1.840744</td>\n",
       "      <td>1.740009</td>\n",
       "      <td>0.369845</td>\n",
       "      <td>0.484037</td>\n",
       "      <td>0.187594</td>\n",
       "      <td>1.842673</td>\n",
       "      <td>0.856627</td>\n",
       "      <td>0.474424</td>\n",
       "      <td>0.415397</td>\n",
       "      <td>0.175614</td>\n",
       "      <td>0.584676</td>\n",
       "      <td>1.208085</td>\n",
       "      <td>0.214748</td>\n",
       "      <td>0.144198</td>\n",
       "      <td>0.120753</td>\n",
       "      <td>1.297408</td>\n",
       "      <td>0.761949</td>\n",
       "      <td>0.354184</td>\n",
       "      <td>0.166404</td>\n",
       "      <td>0.099637</td>\n",
       "      <td>1.422160</td>\n",
       "      <td>0.889572</td>\n",
       "      <td>0.552382</td>\n",
       "      <td>0.149173</td>\n",
       "      <td>0.136558</td>\n",
       "      <td>2.078273</td>\n",
       "      <td>1.472955</td>\n",
       "      <td>1.057647</td>\n",
       "      <td>0.280043</td>\n",
       "      <td>0.153327</td>\n",
       "      <td>1.409152</td>\n",
       "      <td>0.979982</td>\n",
       "      <td>0.869081</td>\n",
       "      <td>0.417896</td>\n",
       "      <td>0.188206</td>\n",
       "      <td>1.428878</td>\n",
       "      <td>0.877251</td>\n",
       "      <td>0.553363</td>\n",
       "      <td>0.383072</td>\n",
       "      <td>0.112488</td>\n",
       "      <td>2.348271</td>\n",
       "      <td>1.782157</td>\n",
       "      <td>0.644852</td>\n",
       "      <td>0.520060</td>\n",
       "      <td>0.154410</td>\n",
       "      <td>2.349918</td>\n",
       "      <td>2.376053</td>\n",
       "      <td>0.655009</td>\n",
       "      <td>0.613906</td>\n",
       "      <td>1.120513</td>\n",
       "      <td>3.758370</td>\n",
       "      <td>1.583895</td>\n",
       "      <td>0.504567</td>\n",
       "      <td>0.471979</td>\n",
       "      <td>0.138717</td>\n",
       "      <td>1.801014</td>\n",
       "      <td>1.504794</td>\n",
       "      <td>0.258570</td>\n",
       "      <td>0.435745</td>\n",
       "      <td>0.469483</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4201.025879</td>\n",
       "      <td>4188.717773</td>\n",
       "      <td>4280.128418</td>\n",
       "      <td>4236.922852</td>\n",
       "      <td>4209.615234</td>\n",
       "      <td>4152.436035</td>\n",
       "      <td>4130.128418</td>\n",
       "      <td>4149.487305</td>\n",
       "      <td>4149.487305</td>\n",
       "      <td>4157.820313</td>\n",
       "      <td>4583.717773</td>\n",
       "      <td>4376.666504</td>\n",
       "      <td>4392.820313</td>\n",
       "      <td>4488.461426</td>\n",
       "      <td>2.030504</td>\n",
       "      <td>1.509949</td>\n",
       "      <td>0.496135</td>\n",
       "      <td>0.452138</td>\n",
       "      <td>0.194018</td>\n",
       "      <td>1.821380</td>\n",
       "      <td>0.596975</td>\n",
       "      <td>0.685146</td>\n",
       "      <td>0.319841</td>\n",
       "      <td>0.174923</td>\n",
       "      <td>1.941082</td>\n",
       "      <td>1.797096</td>\n",
       "      <td>0.558355</td>\n",
       "      <td>0.485693</td>\n",
       "      <td>0.189281</td>\n",
       "      <td>1.945797</td>\n",
       "      <td>0.943827</td>\n",
       "      <td>0.654867</td>\n",
       "      <td>0.437179</td>\n",
       "      <td>0.175975</td>\n",
       "      <td>0.641788</td>\n",
       "      <td>1.284735</td>\n",
       "      <td>0.212188</td>\n",
       "      <td>0.161631</td>\n",
       "      <td>0.120083</td>\n",
       "      <td>1.522173</td>\n",
       "      <td>0.821546</td>\n",
       "      <td>0.295174</td>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.110549</td>\n",
       "      <td>1.635566</td>\n",
       "      <td>0.813352</td>\n",
       "      <td>0.416753</td>\n",
       "      <td>0.149681</td>\n",
       "      <td>0.127509</td>\n",
       "      <td>2.409505</td>\n",
       "      <td>1.458509</td>\n",
       "      <td>1.079635</td>\n",
       "      <td>0.326943</td>\n",
       "      <td>0.152629</td>\n",
       "      <td>1.462499</td>\n",
       "      <td>0.907250</td>\n",
       "      <td>0.969058</td>\n",
       "      <td>0.482167</td>\n",
       "      <td>0.192056</td>\n",
       "      <td>1.761167</td>\n",
       "      <td>0.858840</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.438183</td>\n",
       "      <td>0.102417</td>\n",
       "      <td>2.969623</td>\n",
       "      <td>1.850320</td>\n",
       "      <td>0.841046</td>\n",
       "      <td>0.601471</td>\n",
       "      <td>0.139706</td>\n",
       "      <td>2.478265</td>\n",
       "      <td>2.495719</td>\n",
       "      <td>0.745543</td>\n",
       "      <td>0.663186</td>\n",
       "      <td>1.769841</td>\n",
       "      <td>4.580270</td>\n",
       "      <td>1.709560</td>\n",
       "      <td>0.606587</td>\n",
       "      <td>0.527616</td>\n",
       "      <td>0.155580</td>\n",
       "      <td>1.859177</td>\n",
       "      <td>1.379617</td>\n",
       "      <td>0.317579</td>\n",
       "      <td>0.468416</td>\n",
       "      <td>0.642560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4203.205078</td>\n",
       "      <td>4182.820313</td>\n",
       "      <td>4282.820313</td>\n",
       "      <td>4231.025879</td>\n",
       "      <td>4207.820313</td>\n",
       "      <td>4172.436035</td>\n",
       "      <td>4131.538574</td>\n",
       "      <td>4147.948730</td>\n",
       "      <td>4131.666504</td>\n",
       "      <td>4131.666504</td>\n",
       "      <td>4574.743652</td>\n",
       "      <td>4377.051270</td>\n",
       "      <td>4390.512695</td>\n",
       "      <td>4483.077148</td>\n",
       "      <td>2.315652</td>\n",
       "      <td>1.541873</td>\n",
       "      <td>0.812744</td>\n",
       "      <td>0.455024</td>\n",
       "      <td>0.193780</td>\n",
       "      <td>1.897375</td>\n",
       "      <td>0.612869</td>\n",
       "      <td>0.982626</td>\n",
       "      <td>0.304586</td>\n",
       "      <td>0.164330</td>\n",
       "      <td>2.164562</td>\n",
       "      <td>1.862794</td>\n",
       "      <td>0.852138</td>\n",
       "      <td>0.483437</td>\n",
       "      <td>0.184689</td>\n",
       "      <td>2.115402</td>\n",
       "      <td>1.042002</td>\n",
       "      <td>0.946591</td>\n",
       "      <td>0.449115</td>\n",
       "      <td>0.172039</td>\n",
       "      <td>0.705399</td>\n",
       "      <td>1.248802</td>\n",
       "      <td>0.220355</td>\n",
       "      <td>0.173320</td>\n",
       "      <td>0.116159</td>\n",
       "      <td>1.822336</td>\n",
       "      <td>0.855601</td>\n",
       "      <td>0.262621</td>\n",
       "      <td>0.212594</td>\n",
       "      <td>0.118272</td>\n",
       "      <td>1.789751</td>\n",
       "      <td>0.748843</td>\n",
       "      <td>0.348561</td>\n",
       "      <td>0.153822</td>\n",
       "      <td>0.115047</td>\n",
       "      <td>2.633745</td>\n",
       "      <td>1.418934</td>\n",
       "      <td>1.177704</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.152218</td>\n",
       "      <td>1.576797</td>\n",
       "      <td>0.863319</td>\n",
       "      <td>1.054493</td>\n",
       "      <td>0.520667</td>\n",
       "      <td>0.193345</td>\n",
       "      <td>2.099791</td>\n",
       "      <td>0.900051</td>\n",
       "      <td>0.864675</td>\n",
       "      <td>0.452751</td>\n",
       "      <td>0.094539</td>\n",
       "      <td>3.570862</td>\n",
       "      <td>1.931157</td>\n",
       "      <td>1.099680</td>\n",
       "      <td>0.659150</td>\n",
       "      <td>0.131624</td>\n",
       "      <td>2.612426</td>\n",
       "      <td>2.580640</td>\n",
       "      <td>0.909882</td>\n",
       "      <td>0.681112</td>\n",
       "      <td>2.377539</td>\n",
       "      <td>5.230789</td>\n",
       "      <td>1.873591</td>\n",
       "      <td>0.795834</td>\n",
       "      <td>0.565414</td>\n",
       "      <td>0.170816</td>\n",
       "      <td>2.027946</td>\n",
       "      <td>1.283876</td>\n",
       "      <td>0.441925</td>\n",
       "      <td>0.494701</td>\n",
       "      <td>0.798197</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4186.538574</td>\n",
       "      <td>4168.717773</td>\n",
       "      <td>4266.794922</td>\n",
       "      <td>4229.230957</td>\n",
       "      <td>4202.179688</td>\n",
       "      <td>4155.384766</td>\n",
       "      <td>4128.333496</td>\n",
       "      <td>4151.666504</td>\n",
       "      <td>4136.666504</td>\n",
       "      <td>4134.230957</td>\n",
       "      <td>4565.512695</td>\n",
       "      <td>4362.436035</td>\n",
       "      <td>4380.897461</td>\n",
       "      <td>4471.025879</td>\n",
       "      <td>2.713728</td>\n",
       "      <td>1.648073</td>\n",
       "      <td>1.184512</td>\n",
       "      <td>0.466466</td>\n",
       "      <td>0.189903</td>\n",
       "      <td>2.000522</td>\n",
       "      <td>0.716119</td>\n",
       "      <td>1.314321</td>\n",
       "      <td>0.311415</td>\n",
       "      <td>0.150169</td>\n",
       "      <td>2.531722</td>\n",
       "      <td>1.999752</td>\n",
       "      <td>1.189854</td>\n",
       "      <td>0.474792</td>\n",
       "      <td>0.176145</td>\n",
       "      <td>2.327959</td>\n",
       "      <td>1.185726</td>\n",
       "      <td>1.291802</td>\n",
       "      <td>0.455347</td>\n",
       "      <td>0.166402</td>\n",
       "      <td>0.761616</td>\n",
       "      <td>1.111277</td>\n",
       "      <td>0.243083</td>\n",
       "      <td>0.176220</td>\n",
       "      <td>0.110383</td>\n",
       "      <td>2.241397</td>\n",
       "      <td>0.836288</td>\n",
       "      <td>0.256094</td>\n",
       "      <td>0.225850</td>\n",
       "      <td>0.121525</td>\n",
       "      <td>1.868363</td>\n",
       "      <td>0.700736</td>\n",
       "      <td>0.350339</td>\n",
       "      <td>0.160516</td>\n",
       "      <td>0.101635</td>\n",
       "      <td>2.665952</td>\n",
       "      <td>1.371016</td>\n",
       "      <td>1.287902</td>\n",
       "      <td>0.380746</td>\n",
       "      <td>0.152630</td>\n",
       "      <td>1.707769</td>\n",
       "      <td>0.879299</td>\n",
       "      <td>1.103137</td>\n",
       "      <td>0.534822</td>\n",
       "      <td>0.192185</td>\n",
       "      <td>2.319043</td>\n",
       "      <td>1.013709</td>\n",
       "      <td>0.973805</td>\n",
       "      <td>0.425609</td>\n",
       "      <td>0.093927</td>\n",
       "      <td>3.970860</td>\n",
       "      <td>2.085875</td>\n",
       "      <td>1.354924</td>\n",
       "      <td>0.674537</td>\n",
       "      <td>0.129551</td>\n",
       "      <td>2.716123</td>\n",
       "      <td>2.642030</td>\n",
       "      <td>1.102290</td>\n",
       "      <td>0.659172</td>\n",
       "      <td>2.746224</td>\n",
       "      <td>5.472836</td>\n",
       "      <td>2.110017</td>\n",
       "      <td>1.021118</td>\n",
       "      <td>0.579656</td>\n",
       "      <td>0.180056</td>\n",
       "      <td>2.265952</td>\n",
       "      <td>1.306188</td>\n",
       "      <td>0.616881</td>\n",
       "      <td>0.506062</td>\n",
       "      <td>0.886495</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4232.436035</td>\n",
       "      <td>4216.922852</td>\n",
       "      <td>4306.922852</td>\n",
       "      <td>4270.769043</td>\n",
       "      <td>4217.436035</td>\n",
       "      <td>4166.538574</td>\n",
       "      <td>4155.897461</td>\n",
       "      <td>4162.820313</td>\n",
       "      <td>4143.461426</td>\n",
       "      <td>4154.487305</td>\n",
       "      <td>4612.436035</td>\n",
       "      <td>4403.333496</td>\n",
       "      <td>4410.641113</td>\n",
       "      <td>4512.179688</td>\n",
       "      <td>3.117646</td>\n",
       "      <td>1.876365</td>\n",
       "      <td>1.521434</td>\n",
       "      <td>0.477338</td>\n",
       "      <td>0.184186</td>\n",
       "      <td>2.088866</td>\n",
       "      <td>0.928602</td>\n",
       "      <td>1.581467</td>\n",
       "      <td>0.343072</td>\n",
       "      <td>0.136723</td>\n",
       "      <td>2.951340</td>\n",
       "      <td>2.249494</td>\n",
       "      <td>1.491825</td>\n",
       "      <td>0.459497</td>\n",
       "      <td>0.165312</td>\n",
       "      <td>2.507987</td>\n",
       "      <td>1.404022</td>\n",
       "      <td>1.596618</td>\n",
       "      <td>0.458486</td>\n",
       "      <td>0.160911</td>\n",
       "      <td>0.790685</td>\n",
       "      <td>0.923368</td>\n",
       "      <td>0.278424</td>\n",
       "      <td>0.170220</td>\n",
       "      <td>0.104968</td>\n",
       "      <td>2.750701</td>\n",
       "      <td>0.770708</td>\n",
       "      <td>0.261437</td>\n",
       "      <td>0.227336</td>\n",
       "      <td>0.120589</td>\n",
       "      <td>1.878548</td>\n",
       "      <td>0.677061</td>\n",
       "      <td>0.406114</td>\n",
       "      <td>0.166363</td>\n",
       "      <td>0.089198</td>\n",
       "      <td>2.480520</td>\n",
       "      <td>1.328967</td>\n",
       "      <td>1.359272</td>\n",
       "      <td>0.377617</td>\n",
       "      <td>0.152640</td>\n",
       "      <td>1.802875</td>\n",
       "      <td>0.974386</td>\n",
       "      <td>1.125059</td>\n",
       "      <td>0.536441</td>\n",
       "      <td>0.188342</td>\n",
       "      <td>2.334140</td>\n",
       "      <td>1.183296</td>\n",
       "      <td>1.031748</td>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.103222</td>\n",
       "      <td>4.028873</td>\n",
       "      <td>2.352159</td>\n",
       "      <td>1.546949</td>\n",
       "      <td>0.644586</td>\n",
       "      <td>0.131259</td>\n",
       "      <td>2.730348</td>\n",
       "      <td>2.709704</td>\n",
       "      <td>1.277430</td>\n",
       "      <td>0.603857</td>\n",
       "      <td>2.744954</td>\n",
       "      <td>5.209275</td>\n",
       "      <td>2.462552</td>\n",
       "      <td>1.230984</td>\n",
       "      <td>0.573620</td>\n",
       "      <td>0.181081</td>\n",
       "      <td>2.461205</td>\n",
       "      <td>1.522420</td>\n",
       "      <td>0.822598</td>\n",
       "      <td>0.498361</td>\n",
       "      <td>0.874455</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68826</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4353.846191</td>\n",
       "      <td>4349.487305</td>\n",
       "      <td>4317.563965</td>\n",
       "      <td>4343.461426</td>\n",
       "      <td>4375.641113</td>\n",
       "      <td>4296.025879</td>\n",
       "      <td>4351.666504</td>\n",
       "      <td>4309.358887</td>\n",
       "      <td>4287.436035</td>\n",
       "      <td>4253.589844</td>\n",
       "      <td>4410.128418</td>\n",
       "      <td>4404.871582</td>\n",
       "      <td>4334.871582</td>\n",
       "      <td>4389.615234</td>\n",
       "      <td>1.794399</td>\n",
       "      <td>1.732103</td>\n",
       "      <td>1.490875</td>\n",
       "      <td>0.889097</td>\n",
       "      <td>0.422814</td>\n",
       "      <td>1.683737</td>\n",
       "      <td>2.825798</td>\n",
       "      <td>1.473751</td>\n",
       "      <td>0.515404</td>\n",
       "      <td>0.335832</td>\n",
       "      <td>1.688582</td>\n",
       "      <td>2.587939</td>\n",
       "      <td>1.603580</td>\n",
       "      <td>0.633181</td>\n",
       "      <td>0.463462</td>\n",
       "      <td>0.970832</td>\n",
       "      <td>2.739399</td>\n",
       "      <td>2.310684</td>\n",
       "      <td>0.796497</td>\n",
       "      <td>0.568299</td>\n",
       "      <td>0.607286</td>\n",
       "      <td>1.006999</td>\n",
       "      <td>1.038713</td>\n",
       "      <td>0.264855</td>\n",
       "      <td>0.174911</td>\n",
       "      <td>0.209593</td>\n",
       "      <td>0.612424</td>\n",
       "      <td>0.630942</td>\n",
       "      <td>0.250562</td>\n",
       "      <td>0.189008</td>\n",
       "      <td>0.342281</td>\n",
       "      <td>0.693480</td>\n",
       "      <td>0.599205</td>\n",
       "      <td>0.270155</td>\n",
       "      <td>0.218111</td>\n",
       "      <td>0.463296</td>\n",
       "      <td>0.975347</td>\n",
       "      <td>0.973423</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.380825</td>\n",
       "      <td>0.499619</td>\n",
       "      <td>0.747713</td>\n",
       "      <td>0.964732</td>\n",
       "      <td>0.601121</td>\n",
       "      <td>0.479798</td>\n",
       "      <td>1.508119</td>\n",
       "      <td>1.508947</td>\n",
       "      <td>1.402304</td>\n",
       "      <td>0.551527</td>\n",
       "      <td>0.407343</td>\n",
       "      <td>2.077217</td>\n",
       "      <td>2.322237</td>\n",
       "      <td>1.981651</td>\n",
       "      <td>1.210345</td>\n",
       "      <td>0.859175</td>\n",
       "      <td>0.807258</td>\n",
       "      <td>1.154451</td>\n",
       "      <td>0.983006</td>\n",
       "      <td>0.363577</td>\n",
       "      <td>0.385067</td>\n",
       "      <td>1.829682</td>\n",
       "      <td>2.088463</td>\n",
       "      <td>0.925704</td>\n",
       "      <td>0.825126</td>\n",
       "      <td>0.576437</td>\n",
       "      <td>2.009375</td>\n",
       "      <td>3.020382</td>\n",
       "      <td>2.115835</td>\n",
       "      <td>1.735570</td>\n",
       "      <td>1.125858</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68827</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4335.769043</td>\n",
       "      <td>4326.538574</td>\n",
       "      <td>4310.641113</td>\n",
       "      <td>4331.153809</td>\n",
       "      <td>4363.333496</td>\n",
       "      <td>4297.179688</td>\n",
       "      <td>4336.025879</td>\n",
       "      <td>4282.563965</td>\n",
       "      <td>4276.410156</td>\n",
       "      <td>4260.641113</td>\n",
       "      <td>4415.641113</td>\n",
       "      <td>4395.897461</td>\n",
       "      <td>4342.948730</td>\n",
       "      <td>4391.794922</td>\n",
       "      <td>1.518506</td>\n",
       "      <td>1.731182</td>\n",
       "      <td>1.309797</td>\n",
       "      <td>0.825882</td>\n",
       "      <td>0.411506</td>\n",
       "      <td>2.088406</td>\n",
       "      <td>2.712901</td>\n",
       "      <td>1.616315</td>\n",
       "      <td>0.525219</td>\n",
       "      <td>0.351573</td>\n",
       "      <td>1.581244</td>\n",
       "      <td>2.407762</td>\n",
       "      <td>1.642157</td>\n",
       "      <td>0.615963</td>\n",
       "      <td>0.464518</td>\n",
       "      <td>0.822325</td>\n",
       "      <td>2.604164</td>\n",
       "      <td>2.294924</td>\n",
       "      <td>0.796594</td>\n",
       "      <td>0.567274</td>\n",
       "      <td>0.562939</td>\n",
       "      <td>0.965336</td>\n",
       "      <td>1.064959</td>\n",
       "      <td>0.244416</td>\n",
       "      <td>0.183303</td>\n",
       "      <td>0.223724</td>\n",
       "      <td>0.567994</td>\n",
       "      <td>0.712354</td>\n",
       "      <td>0.277426</td>\n",
       "      <td>0.190390</td>\n",
       "      <td>0.399511</td>\n",
       "      <td>0.540753</td>\n",
       "      <td>0.635349</td>\n",
       "      <td>0.288893</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>0.494705</td>\n",
       "      <td>0.609523</td>\n",
       "      <td>0.888989</td>\n",
       "      <td>0.381773</td>\n",
       "      <td>0.356592</td>\n",
       "      <td>0.601448</td>\n",
       "      <td>0.557258</td>\n",
       "      <td>0.860495</td>\n",
       "      <td>0.563639</td>\n",
       "      <td>0.480358</td>\n",
       "      <td>1.839645</td>\n",
       "      <td>1.400092</td>\n",
       "      <td>1.304396</td>\n",
       "      <td>0.502376</td>\n",
       "      <td>0.420112</td>\n",
       "      <td>2.964393</td>\n",
       "      <td>2.025547</td>\n",
       "      <td>1.846436</td>\n",
       "      <td>1.212718</td>\n",
       "      <td>0.908223</td>\n",
       "      <td>0.921183</td>\n",
       "      <td>0.947680</td>\n",
       "      <td>0.872257</td>\n",
       "      <td>0.341090</td>\n",
       "      <td>0.380784</td>\n",
       "      <td>2.820868</td>\n",
       "      <td>1.899325</td>\n",
       "      <td>0.833753</td>\n",
       "      <td>0.786224</td>\n",
       "      <td>0.600227</td>\n",
       "      <td>2.505607</td>\n",
       "      <td>2.680849</td>\n",
       "      <td>1.971062</td>\n",
       "      <td>1.468342</td>\n",
       "      <td>1.250918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68828</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4321.666504</td>\n",
       "      <td>4313.205078</td>\n",
       "      <td>4310.000000</td>\n",
       "      <td>4310.384766</td>\n",
       "      <td>4357.436035</td>\n",
       "      <td>4296.025879</td>\n",
       "      <td>4337.563965</td>\n",
       "      <td>4291.153809</td>\n",
       "      <td>4275.256348</td>\n",
       "      <td>4265.384766</td>\n",
       "      <td>4429.743652</td>\n",
       "      <td>4406.025879</td>\n",
       "      <td>4362.051270</td>\n",
       "      <td>4410.897461</td>\n",
       "      <td>1.341573</td>\n",
       "      <td>1.729656</td>\n",
       "      <td>1.131855</td>\n",
       "      <td>0.772729</td>\n",
       "      <td>0.417940</td>\n",
       "      <td>2.651952</td>\n",
       "      <td>2.533644</td>\n",
       "      <td>1.613929</td>\n",
       "      <td>0.540861</td>\n",
       "      <td>0.375915</td>\n",
       "      <td>1.404288</td>\n",
       "      <td>2.189634</td>\n",
       "      <td>1.570219</td>\n",
       "      <td>0.599079</td>\n",
       "      <td>0.473185</td>\n",
       "      <td>0.740845</td>\n",
       "      <td>2.301824</td>\n",
       "      <td>2.034009</td>\n",
       "      <td>0.761918</td>\n",
       "      <td>0.581191</td>\n",
       "      <td>0.499970</td>\n",
       "      <td>0.883228</td>\n",
       "      <td>1.010391</td>\n",
       "      <td>0.224971</td>\n",
       "      <td>0.194204</td>\n",
       "      <td>0.231343</td>\n",
       "      <td>0.522757</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.291406</td>\n",
       "      <td>0.186119</td>\n",
       "      <td>0.494401</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.648592</td>\n",
       "      <td>0.297669</td>\n",
       "      <td>0.221894</td>\n",
       "      <td>0.622651</td>\n",
       "      <td>0.387841</td>\n",
       "      <td>0.782808</td>\n",
       "      <td>0.365088</td>\n",
       "      <td>0.326365</td>\n",
       "      <td>0.773324</td>\n",
       "      <td>0.458880</td>\n",
       "      <td>0.714754</td>\n",
       "      <td>0.519296</td>\n",
       "      <td>0.472614</td>\n",
       "      <td>2.181518</td>\n",
       "      <td>1.307489</td>\n",
       "      <td>1.137089</td>\n",
       "      <td>0.486849</td>\n",
       "      <td>0.437512</td>\n",
       "      <td>4.045822</td>\n",
       "      <td>1.856673</td>\n",
       "      <td>1.619169</td>\n",
       "      <td>1.217632</td>\n",
       "      <td>0.983985</td>\n",
       "      <td>1.060099</td>\n",
       "      <td>0.791917</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>0.330570</td>\n",
       "      <td>0.367243</td>\n",
       "      <td>4.052598</td>\n",
       "      <td>1.743110</td>\n",
       "      <td>0.789346</td>\n",
       "      <td>0.777936</td>\n",
       "      <td>0.631701</td>\n",
       "      <td>3.082165</td>\n",
       "      <td>2.443027</td>\n",
       "      <td>1.868980</td>\n",
       "      <td>1.213362</td>\n",
       "      <td>1.373250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68829</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4334.615234</td>\n",
       "      <td>4316.666504</td>\n",
       "      <td>4318.717773</td>\n",
       "      <td>4339.102539</td>\n",
       "      <td>4370.512695</td>\n",
       "      <td>4297.436035</td>\n",
       "      <td>4333.461426</td>\n",
       "      <td>4297.051270</td>\n",
       "      <td>4281.922852</td>\n",
       "      <td>4266.666504</td>\n",
       "      <td>4452.307617</td>\n",
       "      <td>4412.051270</td>\n",
       "      <td>4373.205078</td>\n",
       "      <td>4399.102539</td>\n",
       "      <td>1.271310</td>\n",
       "      <td>1.729621</td>\n",
       "      <td>0.996775</td>\n",
       "      <td>0.727697</td>\n",
       "      <td>0.426497</td>\n",
       "      <td>3.227450</td>\n",
       "      <td>2.334565</td>\n",
       "      <td>1.476897</td>\n",
       "      <td>0.541562</td>\n",
       "      <td>0.398260</td>\n",
       "      <td>1.178322</td>\n",
       "      <td>1.966231</td>\n",
       "      <td>1.401235</td>\n",
       "      <td>0.580439</td>\n",
       "      <td>0.486637</td>\n",
       "      <td>0.699656</td>\n",
       "      <td>1.909098</td>\n",
       "      <td>1.615258</td>\n",
       "      <td>0.692173</td>\n",
       "      <td>0.593207</td>\n",
       "      <td>0.423881</td>\n",
       "      <td>0.785338</td>\n",
       "      <td>0.888115</td>\n",
       "      <td>0.202566</td>\n",
       "      <td>0.203287</td>\n",
       "      <td>0.235859</td>\n",
       "      <td>0.472737</td>\n",
       "      <td>0.707624</td>\n",
       "      <td>0.287502</td>\n",
       "      <td>0.176929</td>\n",
       "      <td>0.621711</td>\n",
       "      <td>0.428318</td>\n",
       "      <td>0.621702</td>\n",
       "      <td>0.292954</td>\n",
       "      <td>0.223516</td>\n",
       "      <td>0.841258</td>\n",
       "      <td>0.286966</td>\n",
       "      <td>0.679799</td>\n",
       "      <td>0.341380</td>\n",
       "      <td>0.295397</td>\n",
       "      <td>1.008611</td>\n",
       "      <td>0.448699</td>\n",
       "      <td>0.568383</td>\n",
       "      <td>0.472231</td>\n",
       "      <td>0.459107</td>\n",
       "      <td>2.482729</td>\n",
       "      <td>1.211401</td>\n",
       "      <td>0.938144</td>\n",
       "      <td>0.488361</td>\n",
       "      <td>0.453905</td>\n",
       "      <td>5.110170</td>\n",
       "      <td>1.780948</td>\n",
       "      <td>1.379879</td>\n",
       "      <td>1.213341</td>\n",
       "      <td>1.076385</td>\n",
       "      <td>1.207596</td>\n",
       "      <td>0.687251</td>\n",
       "      <td>0.594865</td>\n",
       "      <td>0.321608</td>\n",
       "      <td>0.346657</td>\n",
       "      <td>5.277864</td>\n",
       "      <td>1.603054</td>\n",
       "      <td>0.781398</td>\n",
       "      <td>0.792152</td>\n",
       "      <td>0.661582</td>\n",
       "      <td>3.607407</td>\n",
       "      <td>2.341642</td>\n",
       "      <td>1.780673</td>\n",
       "      <td>0.982586</td>\n",
       "      <td>1.449505</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68830</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4328.589844</td>\n",
       "      <td>4308.589844</td>\n",
       "      <td>4310.384766</td>\n",
       "      <td>4327.820313</td>\n",
       "      <td>4357.692383</td>\n",
       "      <td>4287.692383</td>\n",
       "      <td>4316.282227</td>\n",
       "      <td>4290.641113</td>\n",
       "      <td>4276.666504</td>\n",
       "      <td>4255.128418</td>\n",
       "      <td>4425.512695</td>\n",
       "      <td>4404.615234</td>\n",
       "      <td>4362.179688</td>\n",
       "      <td>4407.820313</td>\n",
       "      <td>1.280377</td>\n",
       "      <td>1.709464</td>\n",
       "      <td>0.944044</td>\n",
       "      <td>0.686657</td>\n",
       "      <td>0.427114</td>\n",
       "      <td>3.620708</td>\n",
       "      <td>2.133070</td>\n",
       "      <td>1.261356</td>\n",
       "      <td>0.519062</td>\n",
       "      <td>0.409512</td>\n",
       "      <td>0.941721</td>\n",
       "      <td>1.750229</td>\n",
       "      <td>1.196412</td>\n",
       "      <td>0.558984</td>\n",
       "      <td>0.501876</td>\n",
       "      <td>0.686955</td>\n",
       "      <td>1.517663</td>\n",
       "      <td>1.171184</td>\n",
       "      <td>0.605487</td>\n",
       "      <td>0.587883</td>\n",
       "      <td>0.359144</td>\n",
       "      <td>0.696308</td>\n",
       "      <td>0.736287</td>\n",
       "      <td>0.177012</td>\n",
       "      <td>0.206533</td>\n",
       "      <td>0.239487</td>\n",
       "      <td>0.414915</td>\n",
       "      <td>0.630719</td>\n",
       "      <td>0.265107</td>\n",
       "      <td>0.163817</td>\n",
       "      <td>0.774873</td>\n",
       "      <td>0.415458</td>\n",
       "      <td>0.568010</td>\n",
       "      <td>0.275544</td>\n",
       "      <td>0.222460</td>\n",
       "      <td>1.104753</td>\n",
       "      <td>0.259265</td>\n",
       "      <td>0.613953</td>\n",
       "      <td>0.319029</td>\n",
       "      <td>0.266309</td>\n",
       "      <td>1.246049</td>\n",
       "      <td>0.501280</td>\n",
       "      <td>0.470419</td>\n",
       "      <td>0.433403</td>\n",
       "      <td>0.439874</td>\n",
       "      <td>2.625043</td>\n",
       "      <td>1.116276</td>\n",
       "      <td>0.763972</td>\n",
       "      <td>0.495242</td>\n",
       "      <td>0.461906</td>\n",
       "      <td>5.786362</td>\n",
       "      <td>1.746933</td>\n",
       "      <td>1.209192</td>\n",
       "      <td>1.192294</td>\n",
       "      <td>1.159012</td>\n",
       "      <td>1.302680</td>\n",
       "      <td>0.615887</td>\n",
       "      <td>0.497628</td>\n",
       "      <td>0.309595</td>\n",
       "      <td>0.323940</td>\n",
       "      <td>6.116080</td>\n",
       "      <td>1.474767</td>\n",
       "      <td>0.820618</td>\n",
       "      <td>0.819320</td>\n",
       "      <td>0.675726</td>\n",
       "      <td>3.863732</td>\n",
       "      <td>2.350165</td>\n",
       "      <td>1.698847</td>\n",
       "      <td>0.801526</td>\n",
       "      <td>1.448685</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68831 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       video_id  subject_id      EEG.AF3       EEG.F7       EEG.F3  \\\n",
       "0             0           0  4210.641113  4179.102539  4287.948730   \n",
       "1             0           0  4201.025879  4188.717773  4280.128418   \n",
       "2             0           0  4203.205078  4182.820313  4282.820313   \n",
       "3             0           0  4186.538574  4168.717773  4266.794922   \n",
       "4             0           0  4232.436035  4216.922852  4306.922852   \n",
       "...         ...         ...          ...          ...          ...   \n",
       "68826        10           7  4353.846191  4349.487305  4317.563965   \n",
       "68827        10           7  4335.769043  4326.538574  4310.641113   \n",
       "68828        10           7  4321.666504  4313.205078  4310.000000   \n",
       "68829        10           7  4334.615234  4316.666504  4318.717773   \n",
       "68830        10           7  4328.589844  4308.589844  4310.384766   \n",
       "\n",
       "           EEG.FC5       EEG.T7       EEG.P7       EEG.O1       EEG.O2  \\\n",
       "0      4235.384766  4207.948730  4165.000000  4135.897461  4170.000000   \n",
       "1      4236.922852  4209.615234  4152.436035  4130.128418  4149.487305   \n",
       "2      4231.025879  4207.820313  4172.436035  4131.538574  4147.948730   \n",
       "3      4229.230957  4202.179688  4155.384766  4128.333496  4151.666504   \n",
       "4      4270.769043  4217.436035  4166.538574  4155.897461  4162.820313   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "68826  4343.461426  4375.641113  4296.025879  4351.666504  4309.358887   \n",
       "68827  4331.153809  4363.333496  4297.179688  4336.025879  4282.563965   \n",
       "68828  4310.384766  4357.436035  4296.025879  4337.563965  4291.153809   \n",
       "68829  4339.102539  4370.512695  4297.436035  4333.461426  4297.051270   \n",
       "68830  4327.820313  4357.692383  4287.692383  4316.282227  4290.641113   \n",
       "\n",
       "            EEG.P8       EEG.T8      EEG.FC6       EEG.F4       EEG.F8  \\\n",
       "0      4155.384766  4157.179688  4610.384766  4388.846191  4413.461426   \n",
       "1      4149.487305  4157.820313  4583.717773  4376.666504  4392.820313   \n",
       "2      4131.666504  4131.666504  4574.743652  4377.051270  4390.512695   \n",
       "3      4136.666504  4134.230957  4565.512695  4362.436035  4380.897461   \n",
       "4      4143.461426  4154.487305  4612.436035  4403.333496  4410.641113   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "68826  4287.436035  4253.589844  4410.128418  4404.871582  4334.871582   \n",
       "68827  4276.410156  4260.641113  4415.641113  4395.897461  4342.948730   \n",
       "68828  4275.256348  4265.384766  4429.743652  4406.025879  4362.051270   \n",
       "68829  4281.922852  4266.666504  4452.307617  4412.051270  4373.205078   \n",
       "68830  4276.666504  4255.128418  4425.512695  4404.615234  4362.179688   \n",
       "\n",
       "           EEG.AF4  POW.AF3.Theta  POW.AF3.Alpha  POW.AF3.BetaL  \\\n",
       "0      4499.743652       1.859064       1.488007       0.294396   \n",
       "1      4488.461426       2.030504       1.509949       0.496135   \n",
       "2      4483.077148       2.315652       1.541873       0.812744   \n",
       "3      4471.025879       2.713728       1.648073       1.184512   \n",
       "4      4512.179688       3.117646       1.876365       1.521434   \n",
       "...            ...            ...            ...            ...   \n",
       "68826  4389.615234       1.794399       1.732103       1.490875   \n",
       "68827  4391.794922       1.518506       1.731182       1.309797   \n",
       "68828  4410.897461       1.341573       1.729656       1.131855   \n",
       "68829  4399.102539       1.271310       1.729621       0.996775   \n",
       "68830  4407.820313       1.280377       1.709464       0.944044   \n",
       "\n",
       "       POW.AF3.BetaH  POW.AF3.Gamma  POW.F7.Theta  POW.F7.Alpha  POW.F7.BetaL  \\\n",
       "0           0.459987       0.188314      1.779598      0.620659      0.497043   \n",
       "1           0.452138       0.194018      1.821380      0.596975      0.685146   \n",
       "2           0.455024       0.193780      1.897375      0.612869      0.982626   \n",
       "3           0.466466       0.189903      2.000522      0.716119      1.314321   \n",
       "4           0.477338       0.184186      2.088866      0.928602      1.581467   \n",
       "...              ...            ...           ...           ...           ...   \n",
       "68826       0.889097       0.422814      1.683737      2.825798      1.473751   \n",
       "68827       0.825882       0.411506      2.088406      2.712901      1.616315   \n",
       "68828       0.772729       0.417940      2.651952      2.533644      1.613929   \n",
       "68829       0.727697       0.426497      3.227450      2.334565      1.476897   \n",
       "68830       0.686657       0.427114      3.620708      2.133070      1.261356   \n",
       "\n",
       "       POW.F7.BetaH  POW.F7.Gamma  POW.F3.Theta  POW.F3.Alpha  POW.F3.BetaL  \\\n",
       "0          0.344509      0.178338      1.840744      1.740009      0.369845   \n",
       "1          0.319841      0.174923      1.941082      1.797096      0.558355   \n",
       "2          0.304586      0.164330      2.164562      1.862794      0.852138   \n",
       "3          0.311415      0.150169      2.531722      1.999752      1.189854   \n",
       "4          0.343072      0.136723      2.951340      2.249494      1.491825   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.515404      0.335832      1.688582      2.587939      1.603580   \n",
       "68827      0.525219      0.351573      1.581244      2.407762      1.642157   \n",
       "68828      0.540861      0.375915      1.404288      2.189634      1.570219   \n",
       "68829      0.541562      0.398260      1.178322      1.966231      1.401235   \n",
       "68830      0.519062      0.409512      0.941721      1.750229      1.196412   \n",
       "\n",
       "       POW.F3.BetaH  POW.F3.Gamma  POW.FC5.Theta  POW.FC5.Alpha  \\\n",
       "0          0.484037      0.187594       1.842673       0.856627   \n",
       "1          0.485693      0.189281       1.945797       0.943827   \n",
       "2          0.483437      0.184689       2.115402       1.042002   \n",
       "3          0.474792      0.176145       2.327959       1.185726   \n",
       "4          0.459497      0.165312       2.507987       1.404022   \n",
       "...             ...           ...            ...            ...   \n",
       "68826      0.633181      0.463462       0.970832       2.739399   \n",
       "68827      0.615963      0.464518       0.822325       2.604164   \n",
       "68828      0.599079      0.473185       0.740845       2.301824   \n",
       "68829      0.580439      0.486637       0.699656       1.909098   \n",
       "68830      0.558984      0.501876       0.686955       1.517663   \n",
       "\n",
       "       POW.FC5.BetaL  POW.FC5.BetaH  POW.FC5.Gamma  POW.T7.Theta  \\\n",
       "0           0.474424       0.415397       0.175614      0.584676   \n",
       "1           0.654867       0.437179       0.175975      0.641788   \n",
       "2           0.946591       0.449115       0.172039      0.705399   \n",
       "3           1.291802       0.455347       0.166402      0.761616   \n",
       "4           1.596618       0.458486       0.160911      0.790685   \n",
       "...              ...            ...            ...           ...   \n",
       "68826       2.310684       0.796497       0.568299      0.607286   \n",
       "68827       2.294924       0.796594       0.567274      0.562939   \n",
       "68828       2.034009       0.761918       0.581191      0.499970   \n",
       "68829       1.615258       0.692173       0.593207      0.423881   \n",
       "68830       1.171184       0.605487       0.587883      0.359144   \n",
       "\n",
       "       POW.T7.Alpha  POW.T7.BetaL  POW.T7.BetaH  POW.T7.Gamma  POW.P7.Theta  \\\n",
       "0          1.208085      0.214748      0.144198      0.120753      1.297408   \n",
       "1          1.284735      0.212188      0.161631      0.120083      1.522173   \n",
       "2          1.248802      0.220355      0.173320      0.116159      1.822336   \n",
       "3          1.111277      0.243083      0.176220      0.110383      2.241397   \n",
       "4          0.923368      0.278424      0.170220      0.104968      2.750701   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      1.006999      1.038713      0.264855      0.174911      0.209593   \n",
       "68827      0.965336      1.064959      0.244416      0.183303      0.223724   \n",
       "68828      0.883228      1.010391      0.224971      0.194204      0.231343   \n",
       "68829      0.785338      0.888115      0.202566      0.203287      0.235859   \n",
       "68830      0.696308      0.736287      0.177012      0.206533      0.239487   \n",
       "\n",
       "       POW.P7.Alpha  POW.P7.BetaL  POW.P7.BetaH  POW.P7.Gamma  POW.O1.Theta  \\\n",
       "0          0.761949      0.354184      0.166404      0.099637      1.422160   \n",
       "1          0.821546      0.295174      0.191005      0.110549      1.635566   \n",
       "2          0.855601      0.262621      0.212594      0.118272      1.789751   \n",
       "3          0.836288      0.256094      0.225850      0.121525      1.868363   \n",
       "4          0.770708      0.261437      0.227336      0.120589      1.878548   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.612424      0.630942      0.250562      0.189008      0.342281   \n",
       "68827      0.567994      0.712354      0.277426      0.190390      0.399511   \n",
       "68828      0.522757      0.740618      0.291406      0.186119      0.494401   \n",
       "68829      0.472737      0.707624      0.287502      0.176929      0.621711   \n",
       "68830      0.414915      0.630719      0.265107      0.163817      0.774873   \n",
       "\n",
       "       POW.O1.Alpha  POW.O1.BetaL  POW.O1.BetaH  POW.O1.Gamma  POW.O2.Theta  \\\n",
       "0          0.889572      0.552382      0.149173      0.136558      2.078273   \n",
       "1          0.813352      0.416753      0.149681      0.127509      2.409505   \n",
       "2          0.748843      0.348561      0.153822      0.115047      2.633745   \n",
       "3          0.700736      0.350339      0.160516      0.101635      2.665952   \n",
       "4          0.677061      0.406114      0.166363      0.089198      2.480520   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.693480      0.599205      0.270155      0.218111      0.463296   \n",
       "68827      0.540753      0.635349      0.288893      0.219653      0.494705   \n",
       "68828      0.460100      0.648592      0.297669      0.221894      0.622651   \n",
       "68829      0.428318      0.621702      0.292954      0.223516      0.841258   \n",
       "68830      0.415458      0.568010      0.275544      0.222460      1.104753   \n",
       "\n",
       "       POW.O2.Alpha  POW.O2.BetaL  POW.O2.BetaH  POW.O2.Gamma  POW.P8.Theta  \\\n",
       "0          1.472955      1.057647      0.280043      0.153327      1.409152   \n",
       "1          1.458509      1.079635      0.326943      0.152629      1.462499   \n",
       "2          1.418934      1.177704      0.363531      0.152218      1.576797   \n",
       "3          1.371016      1.287902      0.380746      0.152630      1.707769   \n",
       "4          1.328967      1.359272      0.377617      0.152640      1.802875   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.975347      0.973423      0.391275      0.380825      0.499619   \n",
       "68827      0.609523      0.888989      0.381773      0.356592      0.601448   \n",
       "68828      0.387841      0.782808      0.365088      0.326365      0.773324   \n",
       "68829      0.286966      0.679799      0.341380      0.295397      1.008611   \n",
       "68830      0.259265      0.613953      0.319029      0.266309      1.246049   \n",
       "\n",
       "       POW.P8.Alpha  POW.P8.BetaL  POW.P8.BetaH  POW.P8.Gamma  POW.T8.Theta  \\\n",
       "0          0.979982      0.869081      0.417896      0.188206      1.428878   \n",
       "1          0.907250      0.969058      0.482167      0.192056      1.761167   \n",
       "2          0.863319      1.054493      0.520667      0.193345      2.099791   \n",
       "3          0.879299      1.103137      0.534822      0.192185      2.319043   \n",
       "4          0.974386      1.125059      0.536441      0.188342      2.334140   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.747713      0.964732      0.601121      0.479798      1.508119   \n",
       "68827      0.557258      0.860495      0.563639      0.480358      1.839645   \n",
       "68828      0.458880      0.714754      0.519296      0.472614      2.181518   \n",
       "68829      0.448699      0.568383      0.472231      0.459107      2.482729   \n",
       "68830      0.501280      0.470419      0.433403      0.439874      2.625043   \n",
       "\n",
       "       POW.T8.Alpha  POW.T8.BetaL  POW.T8.BetaH  POW.T8.Gamma  POW.FC6.Theta  \\\n",
       "0          0.877251      0.553363      0.383072      0.112488       2.348271   \n",
       "1          0.858840      0.714015      0.438183      0.102417       2.969623   \n",
       "2          0.900051      0.864675      0.452751      0.094539       3.570862   \n",
       "3          1.013709      0.973805      0.425609      0.093927       3.970860   \n",
       "4          1.183296      1.031748      0.371362      0.103222       4.028873   \n",
       "...             ...           ...           ...           ...            ...   \n",
       "68826      1.508947      1.402304      0.551527      0.407343       2.077217   \n",
       "68827      1.400092      1.304396      0.502376      0.420112       2.964393   \n",
       "68828      1.307489      1.137089      0.486849      0.437512       4.045822   \n",
       "68829      1.211401      0.938144      0.488361      0.453905       5.110170   \n",
       "68830      1.116276      0.763972      0.495242      0.461906       5.786362   \n",
       "\n",
       "       POW.FC6.Alpha  POW.FC6.BetaL  POW.FC6.BetaH  POW.FC6.Gamma  \\\n",
       "0           1.782157       0.644852       0.520060       0.154410   \n",
       "1           1.850320       0.841046       0.601471       0.139706   \n",
       "2           1.931157       1.099680       0.659150       0.131624   \n",
       "3           2.085875       1.354924       0.674537       0.129551   \n",
       "4           2.352159       1.546949       0.644586       0.131259   \n",
       "...              ...            ...            ...            ...   \n",
       "68826       2.322237       1.981651       1.210345       0.859175   \n",
       "68827       2.025547       1.846436       1.212718       0.908223   \n",
       "68828       1.856673       1.619169       1.217632       0.983985   \n",
       "68829       1.780948       1.379879       1.213341       1.076385   \n",
       "68830       1.746933       1.209192       1.192294       1.159012   \n",
       "\n",
       "       POW.F4.Theta  POW.F4.Alpha  POW.F4.BetaL  POW.F4.BetaH  POW.F4.Gamma  \\\n",
       "0          2.349918      2.376053      0.655009      0.613906      1.120513   \n",
       "1          2.478265      2.495719      0.745543      0.663186      1.769841   \n",
       "2          2.612426      2.580640      0.909882      0.681112      2.377539   \n",
       "3          2.716123      2.642030      1.102290      0.659172      2.746224   \n",
       "4          2.730348      2.709704      1.277430      0.603857      2.744954   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      0.807258      1.154451      0.983006      0.363577      0.385067   \n",
       "68827      0.921183      0.947680      0.872257      0.341090      0.380784   \n",
       "68828      1.060099      0.791917      0.732240      0.330570      0.367243   \n",
       "68829      1.207596      0.687251      0.594865      0.321608      0.346657   \n",
       "68830      1.302680      0.615887      0.497628      0.309595      0.323940   \n",
       "\n",
       "       POW.F8.Theta  POW.F8.Alpha  POW.F8.BetaL  POW.F8.BetaH  POW.F8.Gamma  \\\n",
       "0          3.758370      1.583895      0.504567      0.471979      0.138717   \n",
       "1          4.580270      1.709560      0.606587      0.527616      0.155580   \n",
       "2          5.230789      1.873591      0.795834      0.565414      0.170816   \n",
       "3          5.472836      2.110017      1.021118      0.579656      0.180056   \n",
       "4          5.209275      2.462552      1.230984      0.573620      0.181081   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "68826      1.829682      2.088463      0.925704      0.825126      0.576437   \n",
       "68827      2.820868      1.899325      0.833753      0.786224      0.600227   \n",
       "68828      4.052598      1.743110      0.789346      0.777936      0.631701   \n",
       "68829      5.277864      1.603054      0.781398      0.792152      0.661582   \n",
       "68830      6.116080      1.474767      0.820618      0.819320      0.675726   \n",
       "\n",
       "       POW.AF4.Theta  POW.AF4.Alpha  POW.AF4.BetaL  POW.AF4.BetaH  \\\n",
       "0           1.801014       1.504794       0.258570       0.435745   \n",
       "1           1.859177       1.379617       0.317579       0.468416   \n",
       "2           2.027946       1.283876       0.441925       0.494701   \n",
       "3           2.265952       1.306188       0.616881       0.506062   \n",
       "4           2.461205       1.522420       0.822598       0.498361   \n",
       "...              ...            ...            ...            ...   \n",
       "68826       2.009375       3.020382       2.115835       1.735570   \n",
       "68827       2.505607       2.680849       1.971062       1.468342   \n",
       "68828       3.082165       2.443027       1.868980       1.213362   \n",
       "68829       3.607407       2.341642       1.780673       0.982586   \n",
       "68830       3.863732       2.350165       1.698847       0.801526   \n",
       "\n",
       "       POW.AF4.Gamma  subject_understood  \n",
       "0           0.469483                   0  \n",
       "1           0.642560                   0  \n",
       "2           0.798197                   0  \n",
       "3           0.886495                   0  \n",
       "4           0.874455                   0  \n",
       "...              ...                 ...  \n",
       "68826       1.125858                   1  \n",
       "68827       1.250918                   1  \n",
       "68828       1.373250                   1  \n",
       "68829       1.449505                   1  \n",
       "68830       1.448685                   1  \n",
       "\n",
       "[68831 rows x 87 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set Pandas options to display more columns\n",
    "pd.options.display.max_columns=100\n",
    "\n",
    "# Read in the eeg data csv\n",
    "df=pd.read_csv('eeg_data.csv', encoding='utf-8')\n",
    "\n",
    "# Show a snaphsot of data\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(datain, time_step):\n",
    "    # 1. y-array  \n",
    "    # First, create an array with indices for y elements based on the chosen time_step\n",
    "    y_indices = np.arange(start=time_step, stop=len(datain), step=time_step)\n",
    "    # Create y array based on the above indices \n",
    "    y_tmp = datain[y_indices]\n",
    "    \n",
    "    # 2. X-array  \n",
    "    # We want to have the same number of rows for X as we do for y\n",
    "    rows_X = len(y_tmp)\n",
    "    # Since the last element in y_tmp may not be the last element of the datain, \n",
    "    # let's ensure that X array stops with the last y\n",
    "    X_tmp = datain[range(time_step*rows_X)]\n",
    "    # Now take this array and reshape it into the desired shape\n",
    "    X_tmp = np.reshape(X_tmp, (rows_X, time_step, 1))\n",
    "    return X_tmp, y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_id\n",
      "subject_id\n",
      "EEG.AF3\n",
      "EEG.F7\n",
      "EEG.F3\n",
      "EEG.FC5\n",
      "EEG.T7\n",
      "EEG.P7\n",
      "EEG.O1\n",
      "EEG.O2\n",
      "EEG.P8\n",
      "EEG.T8\n",
      "EEG.FC6\n",
      "EEG.F4\n",
      "EEG.F8\n",
      "EEG.AF4\n",
      "POW.AF3.Theta\n",
      "POW.AF3.Alpha\n",
      "POW.AF3.BetaL\n",
      "POW.AF3.BetaH\n",
      "POW.AF3.Gamma\n",
      "POW.F7.Theta\n",
      "POW.F7.Alpha\n",
      "POW.F7.BetaL\n",
      "POW.F7.BetaH\n",
      "POW.F7.Gamma\n",
      "POW.F3.Theta\n",
      "POW.F3.Alpha\n",
      "POW.F3.BetaL\n",
      "POW.F3.BetaH\n",
      "POW.F3.Gamma\n",
      "POW.FC5.Theta\n",
      "POW.FC5.Alpha\n",
      "POW.FC5.BetaL\n",
      "POW.FC5.BetaH\n",
      "POW.FC5.Gamma\n",
      "POW.T7.Theta\n",
      "POW.T7.Alpha\n",
      "POW.T7.BetaL\n",
      "POW.T7.BetaH\n",
      "POW.T7.Gamma\n",
      "POW.P7.Theta\n",
      "POW.P7.Alpha\n",
      "POW.P7.BetaL\n",
      "POW.P7.BetaH\n",
      "POW.P7.Gamma\n",
      "POW.O1.Theta\n",
      "POW.O1.Alpha\n",
      "POW.O1.BetaL\n",
      "POW.O1.BetaH\n",
      "POW.O1.Gamma\n",
      "POW.O2.Theta\n",
      "POW.O2.Alpha\n",
      "POW.O2.BetaL\n",
      "POW.O2.BetaH\n",
      "POW.O2.Gamma\n",
      "POW.P8.Theta\n",
      "POW.P8.Alpha\n",
      "POW.P8.BetaL\n",
      "POW.P8.BetaH\n",
      "POW.P8.Gamma\n",
      "POW.T8.Theta\n",
      "POW.T8.Alpha\n",
      "POW.T8.BetaL\n",
      "POW.T8.BetaH\n",
      "POW.T8.Gamma\n",
      "POW.FC6.Theta\n",
      "POW.FC6.Alpha\n",
      "POW.FC6.BetaL\n",
      "POW.FC6.BetaH\n",
      "POW.FC6.Gamma\n",
      "POW.F4.Theta\n",
      "POW.F4.Alpha\n",
      "POW.F4.BetaL\n",
      "POW.F4.BetaH\n",
      "POW.F4.Gamma\n",
      "POW.F8.Theta\n",
      "POW.F8.Alpha\n",
      "POW.F8.BetaL\n",
      "POW.F8.BetaH\n",
      "POW.F8.Gamma\n",
      "POW.AF4.Theta\n",
      "POW.AF4.Alpha\n",
      "POW.AF4.BetaL\n",
      "POW.AF4.BetaH\n",
      "POW.AF4.Gamma\n",
      "subject_understood\n"
     ]
    }
   ],
   "source": [
    "#Read dataset\n",
    "data = pd.read_csv(\"EEG_data.csv\")\n",
    "\n",
    "data = data.dropna(axis=0)\n",
    "for col in data.columns:\n",
    "  print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 ['POW.F7.Alpha', 'POW.F3.Alpha', 'POW.P7.Alpha', 'POW.O1.Alpha', 'POW.O2.Alpha', 'POW.P8.Alpha', 'POW.AF4.Alpha']\n",
      "14 ['POW.F7.BetaL', 'POW.F7.BetaH', 'POW.F3.BetaL', 'POW.F3.BetaH', 'POW.P7.BetaL', 'POW.P7.BetaH', 'POW.O1.BetaL', 'POW.O1.BetaH', 'POW.O2.BetaL', 'POW.O2.BetaH', 'POW.P8.BetaL', 'POW.P8.BetaH', 'POW.AF4.BetaL', 'POW.AF4.BetaH']\n",
      "7 ['POW.F7.Gamma', 'POW.F3.Gamma', 'POW.P7.Gamma', 'POW.O1.Gamma', 'POW.O2.Gamma', 'POW.P8.Gamma', 'POW.AF4.Gamma']\n",
      "7 ['POW.F7.Theta', 'POW.F3.Theta', 'POW.P7.Theta', 'POW.O1.Theta', 'POW.O2.Theta', 'POW.P8.Theta', 'POW.AF4.Theta']\n"
     ]
    }
   ],
   "source": [
    "alpha_cols =[]\n",
    "beta_cols=[]\n",
    "gamma_cols=[]\n",
    "theta_cols=[]\n",
    "\n",
    "channels=[\"F7\", 'F3', 'P7', 'O1', 'O2', 'P8','AF4']\n",
    "\n",
    "for col in data.columns:\n",
    "  col_list=list(col.split(\".\"))\n",
    "  # print(col_list)\n",
    "  if (len(col_list)==3):\n",
    "    if (\"Alpha\" in col_list[2] and col_list[1] in channels):\n",
    "      alpha_cols.append(col)\n",
    "    elif (\"Beta\" in col_list[2] and col_list[1] in channels):\n",
    "      beta_cols.append(col)\n",
    "    elif (\"Gamma\" in col_list[2] and col_list[1] in channels):\n",
    "      gamma_cols.append(col)\n",
    "    elif (\"Theta\" in col_list[2] and col_list[1] in channels):\n",
    "      theta_cols.append(col)\n",
    "print(len(alpha_cols),alpha_cols)\n",
    "print(len(beta_cols),beta_cols)\n",
    "print(len(gamma_cols),gamma_cols)\n",
    "print(len(theta_cols),theta_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1.138560\n",
      "1        1.110621\n",
      "2        1.092319\n",
      "3        1.115628\n",
      "4        1.207377\n",
      "           ...   \n",
      "68826    1.637583\n",
      "68827    1.439577\n",
      "68828    1.285126\n",
      "68829    1.182737\n",
      "68830    1.117769\n",
      "Length: 68831, dtype: float64 0        0.445469\n",
      "1        0.481818\n",
      "2        0.546672\n",
      "3        0.622338\n",
      "4        0.689747\n",
      "           ...   \n",
      "68826    0.911338\n",
      "68827    0.889141\n",
      "68828    0.840476\n",
      "68829    0.766783\n",
      "68830    0.686598\n",
      "Length: 68831, dtype: float64 0        0.201878\n",
      "1        0.227072\n",
      "2        0.246585\n",
      "3        0.254398\n",
      "4        0.246751\n",
      "           ...   \n",
      "68826    0.456128\n",
      "68827    0.473429\n",
      "68828    0.489906\n",
      "68829    0.498479\n",
      "68830    0.493219\n",
      "Length: 68831, dtype: float64 0        1.661193\n",
      "1        1.807340\n",
      "2        1.987502\n",
      "3        2.183097\n",
      "4        2.344865\n",
      "           ...   \n",
      "68826    0.985212\n",
      "68827    1.127806\n",
      "68828    1.322875\n",
      "68829    1.531517\n",
      "68830    1.684475\n",
      "Length: 68831, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "alpha=data[alpha_cols].mean(axis=1)\n",
    "beta=data[beta_cols].mean(axis=1)\n",
    "gamma=data[gamma_cols].mean(axis=1)\n",
    "theta=data[theta_cols].mean(axis=1)\n",
    "print(alpha,beta,gamma,theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ABTR= BETA/(APHA+THETA)\n",
    "#AGR = APHA/GAMMA\n",
    "#TBR = THETA/BETA\n",
    "\n",
    "abtr = []\n",
    "agr = []\n",
    "tbr = []\n",
    "\n",
    "for (a,b,g,t) in zip(alpha,beta,gamma,theta):\n",
    "  feature_abtr = b/(a+t)\n",
    "  abtr.append(feature_abtr)\n",
    "\n",
    "  feature_agr = a/g\n",
    "  agr.append(feature_agr)\n",
    "\n",
    "  feature_tbr = t/b\n",
    "  tbr.append(feature_tbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           abtr       agr       tbr\n",
      "0      0.159110  5.639854  3.729091\n",
      "1      0.165121  4.891042  3.751088\n",
      "2      0.177501  4.429781  3.635639\n",
      "3      0.188660  4.385371  3.507896\n",
      "4      0.194172  4.893092  3.399601\n",
      "...         ...       ...       ...\n",
      "68826  0.347468  3.590186  1.081061\n",
      "68827  0.346322  3.040747  1.268422\n",
      "68828  0.322268  2.623210  1.573960\n",
      "68829  0.282502  2.372693  1.997327\n",
      "68830  0.245017  2.266273  2.453364\n",
      "\n",
      "[68831 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(abtr, agr,tbr)),columns =['abtr', 'agr','tbr'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train            abtr        agr        tbr\n",
      "56390  0.099961   7.313723   6.453630\n",
      "24912  0.093007  14.474470   7.356275\n",
      "24822  0.071271   8.326097  10.602472\n",
      "44236  0.094514  13.288529   6.874982\n",
      "45248  0.295440   2.178452   2.445405\n",
      "...         ...        ...        ...\n",
      "37194  0.101508   5.145293   7.377970\n",
      "6265   0.140753   7.720524   4.387119\n",
      "54886  0.159160   2.780806   3.890348\n",
      "860    0.253000  13.462422   1.492623\n",
      "15795  0.054422  13.184494  15.426566\n",
      "\n",
      "[55064 rows x 3 columns] \n",
      " x test            abtr       agr        tbr\n",
      "54873  0.110897  1.846611   6.063296\n",
      "20237  0.105888  3.823915   4.119782\n",
      "14792  0.092837  4.366782   7.610283\n",
      "61165  0.263019  2.244861   2.808181\n",
      "18846  0.215169  4.710587   3.213026\n",
      "...         ...       ...        ...\n",
      "39844  0.070484  6.202890   9.031889\n",
      "45314  0.232904  2.064100   2.960710\n",
      "19260  0.176346  3.128294   4.232881\n",
      "10646  0.039609  6.277639  22.739621\n",
      "18994  0.267726  5.010608   2.534767\n",
      "\n",
      "[13767 rows x 3 columns] \n",
      " y train 56390    1\n",
      "24912    1\n",
      "24822    1\n",
      "44236    1\n",
      "45248    1\n",
      "        ..\n",
      "37194    1\n",
      "6265     0\n",
      "54886    1\n",
      "860      0\n",
      "15795    0\n",
      "Name: subject_understood, Length: 55064, dtype: int64 \n",
      " y test 54873    1\n",
      "20237    1\n",
      "14792    0\n",
      "61165    1\n",
      "18846    1\n",
      "        ..\n",
      "39844    1\n",
      "45314    1\n",
      "19260    1\n",
      "10646    0\n",
      "18994    1\n",
      "Name: subject_understood, Length: 13767, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#x_int holds all the input that will train the machine learning model\n",
    "x_int = df\n",
    "\n",
    "# #y_int contains the output/label to indicate whether the subject understood the lecture or not \n",
    "y_int = data[\"subject_understood\"]\n",
    "\n",
    "# y_int = y_int.dropna(axis=0)\n",
    "# x_int = x_int.dropna(axis=0)\n",
    "# y_int = y_int.values\n",
    "# x_int = x_int.values\n",
    "\n",
    "# #Using 80% of data to train the model and 20% of the data to test the model\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_int, y_int, test_size=0.2,random_state=42)\n",
    "print('x train',x_train,'\\n x test', x_test,'\\n y train', y_train,'\\n y test', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55064, 3)\n",
      "(55064,)\n",
      "(13767, 3)\n",
      "(13767,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "861/861 [==============================] - 4s 3ms/step - loss: 0.4398 - accuracy: 0.8173\n",
      "Epoch 2/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4314 - accuracy: 0.8197\n",
      "Epoch 3/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4288 - accuracy: 0.8210\n",
      "Epoch 4/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4277 - accuracy: 0.8206\n",
      "Epoch 5/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4259 - accuracy: 0.8204\n",
      "Epoch 6/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4255 - accuracy: 0.8209\n",
      "Epoch 7/80\n",
      "861/861 [==============================] - 3s 3ms/step - loss: 0.4248 - accuracy: 0.8208\n",
      "Epoch 8/80\n",
      "861/861 [==============================] - 2s 3ms/step - loss: 0.4236 - accuracy: 0.8211\n",
      "Epoch 9/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4224 - accuracy: 0.8214\n",
      "Epoch 10/80\n",
      "861/861 [==============================] - 2s 3ms/step - loss: 0.4224 - accuracy: 0.8216\n",
      "Epoch 11/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4209 - accuracy: 0.8216\n",
      "Epoch 12/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4200 - accuracy: 0.8223\n",
      "Epoch 13/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4194 - accuracy: 0.8221\n",
      "Epoch 14/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4181 - accuracy: 0.8220\n",
      "Epoch 15/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4170 - accuracy: 0.8235\n",
      "Epoch 16/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4157 - accuracy: 0.8241\n",
      "Epoch 17/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4145 - accuracy: 0.8243\n",
      "Epoch 18/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4133 - accuracy: 0.8251\n",
      "Epoch 19/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4127 - accuracy: 0.8259\n",
      "Epoch 20/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4114 - accuracy: 0.8249\n",
      "Epoch 21/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4105 - accuracy: 0.8269\n",
      "Epoch 22/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4109 - accuracy: 0.8258\n",
      "Epoch 23/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4100 - accuracy: 0.8253\n",
      "Epoch 24/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.8261\n",
      "Epoch 25/80\n",
      "861/861 [==============================] - 2s 3ms/step - loss: 0.4084 - accuracy: 0.8274\n",
      "Epoch 26/80\n",
      "861/861 [==============================] - 2s 3ms/step - loss: 0.4077 - accuracy: 0.8273\n",
      "Epoch 27/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8286\n",
      "Epoch 28/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4076 - accuracy: 0.8277\n",
      "Epoch 29/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4070 - accuracy: 0.8285\n",
      "Epoch 30/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4063 - accuracy: 0.8293\n",
      "Epoch 31/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4062 - accuracy: 0.8294\n",
      "Epoch 32/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4064 - accuracy: 0.8287\n",
      "Epoch 33/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4057 - accuracy: 0.8293\n",
      "Epoch 34/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4057 - accuracy: 0.8298\n",
      "Epoch 35/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4055 - accuracy: 0.8289\n",
      "Epoch 36/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4052 - accuracy: 0.8288\n",
      "Epoch 37/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8297\n",
      "Epoch 38/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4040 - accuracy: 0.8296\n",
      "Epoch 39/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8289\n",
      "Epoch 40/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4047 - accuracy: 0.8291\n",
      "Epoch 41/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4041 - accuracy: 0.8301\n",
      "Epoch 42/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8305\n",
      "Epoch 43/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4036 - accuracy: 0.8296\n",
      "Epoch 44/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4041 - accuracy: 0.8295\n",
      "Epoch 45/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4039 - accuracy: 0.8298\n",
      "Epoch 46/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4042 - accuracy: 0.8301\n",
      "Epoch 47/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4033 - accuracy: 0.8306\n",
      "Epoch 48/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4033 - accuracy: 0.8306\n",
      "Epoch 49/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4034 - accuracy: 0.8296\n",
      "Epoch 50/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.8300\n",
      "Epoch 51/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8305\n",
      "Epoch 52/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8302\n",
      "Epoch 53/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4034 - accuracy: 0.8304\n",
      "Epoch 54/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4027 - accuracy: 0.8294\n",
      "Epoch 55/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4031 - accuracy: 0.8295\n",
      "Epoch 56/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4030 - accuracy: 0.8305\n",
      "Epoch 57/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8303\n",
      "Epoch 58/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4022 - accuracy: 0.8306\n",
      "Epoch 59/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4019 - accuracy: 0.8310\n",
      "Epoch 60/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4022 - accuracy: 0.8310\n",
      "Epoch 61/80\n",
      "861/861 [==============================] - 2s 3ms/step - loss: 0.4021 - accuracy: 0.8303\n",
      "Epoch 62/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4024 - accuracy: 0.8307\n",
      "Epoch 63/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4014 - accuracy: 0.8310\n",
      "Epoch 64/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8295\n",
      "Epoch 65/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4020 - accuracy: 0.8313\n",
      "Epoch 66/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4014 - accuracy: 0.8303\n",
      "Epoch 67/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4024 - accuracy: 0.8310\n",
      "Epoch 68/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8319\n",
      "Epoch 69/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4017 - accuracy: 0.8308\n",
      "Epoch 70/80\n",
      "861/861 [==============================] - 1s 1ms/step - loss: 0.4016 - accuracy: 0.8311\n",
      "Epoch 71/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4017 - accuracy: 0.8313\n",
      "Epoch 72/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4011 - accuracy: 0.8317\n",
      "Epoch 73/80\n",
      "861/861 [==============================] - 3s 4ms/step - loss: 0.4017 - accuracy: 0.8309\n",
      "Epoch 74/80\n",
      "861/861 [==============================] - 3s 3ms/step - loss: 0.4011 - accuracy: 0.8315\n",
      "Epoch 75/80\n",
      "861/861 [==============================] - 3s 3ms/step - loss: 0.4015 - accuracy: 0.8318\n",
      "Epoch 76/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4011 - accuracy: 0.8312\n",
      "Epoch 77/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4004 - accuracy: 0.8317\n",
      "Epoch 78/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4014 - accuracy: 0.8305\n",
      "Epoch 79/80\n",
      "861/861 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8312\n",
      "Epoch 80/80\n",
      "861/861 [==============================] - 2s 2ms/step - loss: 0.4006 - accuracy: 0.8314\n",
      "431/431 [==============================] - 1s 1ms/step - loss: 0.3968 - accuracy: 0.8369\n",
      "Test loss: 0.396770179271698\n",
      "Test accuracy: 0.8369289040565491\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(64, input_shape=(3, 1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "x_train=x_train.to_numpy()\n",
    "y_train=y_train.to_numpy()\n",
    "x_test=x_test.to_numpy()\n",
    "y_test=y_test.to_numpy()\n",
    "# Train the model\n",
    "x_train = x_train.reshape((55064, 3, 1))\n",
    "model.fit(x_train, y_train, epochs=80, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "x_test = x_test.reshape((13767, 3, 1))\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
